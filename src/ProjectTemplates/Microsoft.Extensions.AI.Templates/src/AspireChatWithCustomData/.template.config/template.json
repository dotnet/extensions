{
  "$schema": "http://json.schemastore.org/template",
  "author": "Microsoft",
  "classifications": [ "Common", "AI", "Web", "Aspire" ],
  "identity": "Microsoft.Extensions.AI.Templates.WebChat.Aspire.CSharp",
  "name": "AI Chat Web App w/ Aspire",
  "description": "A project template for creating an AI chat application, which uses retrieval-augmented generation (RAG) to chat with your own data.",
  "shortName": "aichatweb-aspire",
  "defaultName": "ChatApp",
  "sourceName": "ChatWithCustomData.Aspire-CSharp",
  "tags": {
    "language": "C#",
    "type": "solution"
  },
  "guids": [
    "d5681fae-b21b-4114-b781-48180f08c0c4"
  ],
  "primaryOutputs": [
    {"path": "./ChatWithCustomData.Aspire-CSharp.sln"},
    {"path": "./README.md"}
  ],
  "sources": [{
    "source": "./",
    "target": "./",
    "modifiers": [
      {
        "rename": {
          "ChatWithCustomData.Aspire-CSharp/": "./"
        }
      }
    ]
  }],
  "symbols": {
    "framework": {
      "type": "parameter",
      "description": "The target framework for the project.",
      "datatype": "choice",
      "choices": [
        {
          "choice": "net9.0",
          "description": "Target net9.0"
        }
      ],
      "replaces": "net9.0",
      "defaultValue": "net9.0",
      "displayName": "Framework"
    },
    "hostIdentifier": {
      "type": "bind",
      "binding": "HostIdentifier"
    },
    "AiServiceProvider": {
      "type": "parameter",
      "displayName": "_AI service provider",
      "datatype": "choice",
      "defaultValue": "githubmodels",
      "choices": [
        {
          "choice": "azureopenai",
          "displayName": "Azure OpenAI",
          "description": "Uses Azure OpenAI service"
        },
        {
          "choice": "githubmodels",
          "displayName": "GitHub Models",
          "description": "Uses GitHub Models"
        },
        {
          "choice": "ollama",
          "displayName": "Ollama (for local development)",
          "description": "Uses Ollama with the llama3.2 and all-minilm models"
        },
        {
          "choice": "openai",
          "displayName": "OpenAI Platform",
          "description": "Uses the OpenAI Platform"
        }
        // {
        //   "choice": "azureaifoundry",
        //   "displayName": "Azure AI Foundry (Preview)",
        //   "description": "Uses Azure AI Foundry (Preview)"
        // }
      ]
    },
    "VectorStore": {
      "type": "parameter",
      "displayName": "_Vector store",
      "datatype": "choice",
      "defaultValue": "qdrant",
      "choices": [
        // {
        //   "choice": "local",
        //   "displayName": "Local on-disk (for prototyping)",
        //   "description": "Uses a JSON file on disk. You can change the implementation to a real vector database before publishing."
        // },
        {
          "choice": "azureaisearch",
          "displayName": "Azure AI Search",
          "description": "Uses Azure AI Search. This also avoids the need to define a data ingestion pipeline, since it's managed by Azure AI Search."
        },
        {
          "choice": "qdrant",
          "displayName": "Qdrant",
          "description": "Uses Qdrant."
        }
      ]
    },
    "IsAzureOpenAI": {
      "type": "computed",
      "value": "(AiServiceProvider == \"azureopenai\")"
    },
    "IsOllama": {
      "type": "computed",
      "value": "(AiServiceProvider == \"ollama\")"
    },
    "UseAzureAISearch": {
      "type": "computed",
      "value": "(VectorStore == \"azureaisearch\")"
    },
    "UseQdrant": {
      "type": "computed",
      "value": "(VectorStore == \"qdrant\")"
    },
    "UseAzure": {
      "type": "computed",
      "value": "(IsAzureOpenAI || IsAzureAiFoundry || UseAzureAISearch)"
    },
    "ChatModel": {
      "type": "parameter",
      "displayName": "Model/deployment for chat completions. Example: gpt-4o-mini",
      "description": "Model/deployment for chat completions. Example: gpt-4o-mini"
    },
    "EmbeddingModel": {
      "type": "parameter",
      "displayName": "Model/deployment for embeddings. Example: text-embedding-3-small",
      "description": "Model/deployment for embeddings. Example: text-embedding-3-small"
    },
    "OpenAiChatModelDefault": {
      "type": "generated",
      "generator": "constant",
      "parameters": {
        "value": "gpt-4o-mini"
      }
    },
    "OpenAiEmbeddingModelDefault": {
      "type": "generated",
      "generator": "constant",
      "parameters": {
        "value": "text-embedding-3-small"
      }
    },
    "OpenAiChatModel": {
      "type": "generated",
      "generator": "coalesce",
      "parameters": {
        "sourceVariableName": "ChatModel",
        "fallbackVariableName": "OpenAiChatModelDefault"
      },
      "replaces": "gpt-4o-mini"
    },
    "OpenAiEmbeddingModel": {
      "type": "generated",
      "generator": "coalesce",
      "parameters": {
        "sourceVariableName": "EmbeddingModel",
        "fallbackVariableName": "OpenAiEmbeddingModelDefault"
      },
      "replaces": "text-embedding-3-small"
    },
    "OllamaChatModelDefault": {
      "type": "generated",
      "generator": "constant",
      "parameters": {
        "value": "llama3.2"
      }
    },
    "OllamaEmbeddingModelDefault": {
      "type": "generated",
      "generator": "constant",
      "parameters": {
        "value": "all-minilm"
      }
    },
    "OllamaChatModel": {
      "type": "generated",
      "generator": "coalesce",
      "parameters": {
        "sourceVariableName": "ChatModel",
        "fallbackVariableName": "OllamaChatModelDefault"
      },
      "replaces": "llama3.2"
    },
    "OllamaEmbeddingModel": {
      "type": "generated",
      "generator": "coalesce",
      "parameters": {
        "sourceVariableName": "EmbeddingModel",
        "fallbackVariableName": "OllamaEmbeddingModelDefault"
      },
      "replaces": "all-minilm"
    },
    "kestrelHttpPort": {
      "type": "parameter",
      "datatype": "integer",
      "description": "Port number to use for the HTTP endpoint in launchSettings.json."
    },
    "kestrelHttpPortGenerated": {
      "type": "generated",
      "generator": "port",
      "parameters": {
        "low": 5000,
        "high": 5300
      }
    },
    "kestrelHttpPortReplacer": {
      "type": "generated",
      "generator": "coalesce",
      "parameters": {
        "sourceVariableName": "kestrelHttpPort",
        "fallbackVariableName": "kestrelHttpPortGenerated"
      },
      "replaces": "5000",
      "onlyIf": [{
        "after": "localhost:"
      }]
    },
    "kestrelHttpsPort": {
      "type": "parameter",
      "datatype": "integer",
      "description": "Port number to use for the HTTPS endpoint in launchSettings.json."
    },
    "kestrelHttpsPortGenerated": {
      "type": "generated",
      "generator": "port",
      "parameters": {
        "low": 7000,
        "high": 7300
      }
    },
    "kestrelHttpsPortReplacer": {
      "type": "generated",
      "generator": "coalesce",
      "parameters": {
        "sourceVariableName": "kestrelHttpsPort",
        "fallbackVariableName": "kestrelHttpsPortGenerated"
      },
      "replaces": "5001",
      "onlyIf": [{
        "after": "localhost:"
      }]
    },
    "vectorStoreIndexNameReplacer": {
      "type": "derived",
      "valueSource": "name",
      "valueTransform": "vectorStoreIndexNameTransform",
      "replaces": "data-ChatWithCustomData.Aspire-CSharp-ingestion"
    }
  },
  "forms": {
    "vectorStoreIndexNameTransform": {
      "identifier": "chain",
      "steps": [
        "lowerCaseForm",
        "vectorStoreIndexName_ReplaceIllegalCharacters",
        "vectoreStoreIndexName_CollapseConsecutiveDashesUnderscores",
        "vectorStoreIndexName_LengthLimit",
        "vectorStoreIndexName_PrefixSuffix"
      ],
      "description": "See https://learn.microsoft.com/rest/api/searchservice/naming-rules"
    },
    "lowerCaseForm": {
      "identifier": "lowerCase"
    },
    "vectorStoreIndexName_ReplaceIllegalCharacters": {
      "identifier": "replace",
      "pattern": "[^a-z0-9-_]",
      "replacement": "_",
      "description": "Only letters, numbers, dashes, and underscores are allowed"
    },
    "vectoreStoreIndexName_CollapseConsecutiveDashesUnderscores": {
      "identifier": "replace",
      "pattern": "([-_])\\1+",
      "replacement": "$1",
      "description": "No consecutive dashes are underscores are allowed"
    },
    "vectorStoreIndexName_LengthLimit": {
      "identifier": "replace",
      "pattern": "^(.{0,114}).*",
      "replacement": "$1",
      "description": "Length is limited to 128 characters, including the 14 characters of prefix and suffix to be added."
    },
    "vectorStoreIndexName_PrefixSuffix": {
      "identifier": "replace",
      "pattern": "^(.*)$",
      "replacement": "data-$1-ingested",
      "description": "Produces a meaningful name parameterized by project name; ensures first, second, and last characters are valid"
    }
  },
  "postActions": [{
    "condition": "(hostIdentifier != \"dotnetcli\")",
    "description": "Opens README file in the editor",
    "manualInstructions": [ ],
    "actionId": "84C0DA21-51C8-4541-9940-6CA19AF04EE6",
    "args": {
      "files": "1"
    },
    "continueOnError": true
  }],
  "SpecialCustomOperations": {
    "**/*.md": {
      "operations": [
        {
          "type": "conditional",
          "configuration": {
            "if": ["#### ---#if"],
            "else": ["#### ---#else"],
            "elseif": ["#### ---#elseif", "#### ---#elif"],
            "endif": ["#### ---#endif"],
            "trim" : "true",
            "wholeLine": "true",
            "evaluator": "C++"
          }
        }
      ]
    }
  }
}
